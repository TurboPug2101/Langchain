{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet  pinecone-client pinecone-text pinecone-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"205fc917-0xxxxxxxxxxxxxxxxb8e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import PineconeHybridSearchRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone is a fully managed vector database, meaning it takes care of infrastructure, scaling, and maintenance. \n",
    "<!--  -->\n",
    "Pinecone runs on the cloud (AWS, GCP, Azure), making it accessible and highly available globally\n",
    "<!--  -->\n",
    "Hybrid Search Capabilities\n",
    "<!--  -->\n",
    "Automatic Scaling and Performance Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GenAi\\Langchain\\newenv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# creating a Pinecone index, which is a vector database used for similarity search and information retrieval tasks.\n",
    "\n",
    "import os\n",
    "from pinecone import Pinecone,ServerlessSpec\n",
    "index_name=\"hybrid-search\"\n",
    "pc=Pinecone(api_key=api_key)\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        # using HF embedd that creates 384 size vector\n",
    "        metric='dotproduct', # good for sparse values\n",
    "        spec=ServerlessSpec(cloud='aws',region=\"us-east-1\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x2016eb00b50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=pc.Index(index_name)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GenAi\\Langchain\\newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# vector embedding and sparse matrix\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up a BM25 text encoder with default settings, which is used to encode text into sparse vectors for efficient keyword-based search in Pinecone.\n",
    "<!--  -->\n",
    "BM25 (Best Matching 25) is a ranking function used by search engines to estimate the relevance of documents to a given search query. It's part of a family of algorithms called probabilistic information retrieval models.\n",
    "Uses TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone_text.sparse.bm25_encoder.BM25Encoder at 0x2011f8ffa10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_text.sparse import BM25Encoder\n",
    "\n",
    "bm25_encoder=BM25Encoder().default()\n",
    "bm25_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  9.78it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences=[\n",
    "    \"In 2023, I visited Paris\",\n",
    "        \"In 2022, I visited New York\",\n",
    "        \"In 2021, I visited New Orleans\",\n",
    "\n",
    "]\n",
    "\n",
    "## tfidf values on these sentence\n",
    "bm25_encoder.fit(sentences)\n",
    "\n",
    "## store the values to a json file\n",
    "bm25_encoder.dump(\"bm25_values.json\")\n",
    "\n",
    "# load to your BM25Encoder object\n",
    "bm25_encoder = BM25Encoder().load(\"bm25_values.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=PineconeHybridSearchRetriever(embeddings=embeddings,sparse_encoder=bm25_encoder,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PineconeHybridSearchRetriever(embeddings=HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False), sparse_encoder=<pinecone_text.sparse.bm25_encoder.BM25Encoder object at 0x000002011F2FFD10>, index=<pinecone.data.index.Index object at 0x000002016EB00B50>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.17s/it]\n"
     ]
    }
   ],
   "source": [
    "retriever.add_texts([\"In 2023, I visited Paris\",\n",
    "        \"In 2022, I visited New York\",\n",
    "        \"In 2021, I visited New Orleans\",\n",
    "]\n",
    ")\n",
    "# texts get added to pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'score': 0.258085757}, page_content='In 2021, I visited New Orleans'),\n",
       " Document(metadata={'score': 0.244448498}, page_content='In 2022, I visited New York'),\n",
       " Document(metadata={'score': 0.220180511}, page_content='In 2023, I visited Paris')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What city did i visit first?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'score': 0.484895855}, page_content='In 2023, I visited Paris'),\n",
       " Document(metadata={'score': 0.374192238}, page_content='In 2022, I visited New York'),\n",
       " Document(metadata={'score': 0.331765205}, page_content='In 2021, I visited New Orleans')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What city did i visit in 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n"
     ]
    }
   ],
   "source": [
    "retriever.add_texts([\n",
    "    \"The Eiffel Tower in Paris is one of the most iconic landmarks in the world, attracting millions of tourists annually.\",\n",
    "    \"The Statue of Liberty in New York symbolizes freedom and is a must-visit for history enthusiasts.\",\n",
    "    \"Mardi Gras in New Orleans is known for its vibrant parades, colorful costumes, and lively street performances.\",\n",
    "    \"The Louvre Museum in Paris houses some of the world's most famous artworks, including the Mona Lisa.\",\n",
    "    \"Central Park in New York offers a serene escape from the city's hustle and bustle, with vast green spaces and scenic views.\",\n",
    "    \"Jazz music in New Orleans has deep roots, with countless clubs offering live performances that capture the city’s soul.\",\n",
    "    \"The cuisine in Paris is a delightful blend of classic French dishes, with famous pastries like croissants and macarons.\",\n",
    "    \"Broadway shows in New York are a major attraction, featuring world-class performances in historic theaters.\",\n",
    "    \"New Orleans’ French Quarter is famous for its rich history, vibrant nightlife, and unique Creole architecture.\",\n",
    "    \"The Seine River in Paris offers scenic boat tours that provide stunning views of the city’s historic bridges and buildings.\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'score': 0.416581571}, page_content='In 2023, I visited Paris'),\n",
       " Document(metadata={'score': 0.334014237}, page_content='The cuisine in Paris is a delightful blend of classic French dishes, with famous pastries like croissants and macarons.'),\n",
       " Document(metadata={'score': 0.284285545}, page_content='The Eiffel Tower in Paris is one of the most iconic landmarks in the world, attracting millions of tourists annually.'),\n",
       " Document(metadata={'score': 0.266835123}, page_content='The Seine River in Paris offers scenic boat tours that provide stunning views of the city’s historic bridges and buildings.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Places in Paris?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'score': 0.390160829}, page_content='Jazz music in New Orleans has deep roots, with countless clubs offering live performances that capture the city’s soul.'),\n",
       " Document(metadata={'score': 0.184022754}, page_content='New Orleans’ French Quarter is famous for its rich history, vibrant nightlife, and unique Creole architecture.'),\n",
       " Document(metadata={'score': 0.145032972}, page_content='In 2021, I visited New Orleans'),\n",
       " Document(metadata={'score': 0.135576591}, page_content='Broadway shows in New York are a major attraction, featuring world-class performances in historic theaters.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"places to enjoy jazz music\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a user searches for \"iconic landmarks in Paris,\" the hybrid search will recognize both \"Eiffel Tower\" (semantic match) and \"Paris\" (keyword match).\n",
    "<!--  -->\n",
    "For a query like \"places to enjoy jazz music,\" the system will intelligently rank the New Orleans text highly, even if \"jazz music\" isn’t an exact keyword match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
